{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from model.models import get_model, metric_dist\n",
    "from tf_dataset.tf_dataset import get_tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train with $\\rho=16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/ji/Dropbox/Robotics/CMSC733/Project1/Phase2/Data\"\n",
    "\n",
    "train_ds = get_tf_dataset(root+\"/Train_Resize\",\n",
    "                          mode=\"unsupervised\",\n",
    "                          do_resize=False,\n",
    "                          rho=16)\n",
    "\n",
    "val_ds = get_tf_dataset(root+\"/Val_Resize\",\n",
    "                          mode=\"unsupervised\",\n",
    "                          do_resize=False,\n",
    "                          rho=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "batch_size = 8\n",
    "monitor_name = \"mae_loss\"\n",
    "checkpoint_path = f\"./chkpt/mdl_unsupervised_rho16\"\n",
    "model = get_model(mode=\"unsupervised\")\n",
    "\n",
    "try:\n",
    "    model.load_weights(checkpoint_path)\n",
    "    print(\"weight loaded\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2e-4,\n",
    "                                              clipvalue=0.01),\n",
    "              run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "steps_per_epoch = int(np.floor(5000/batch_size))\n",
    "    # reduce learning rate when performance plateau\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=monitor_name,\n",
    "                                                factor=0.2,\n",
    "                                                patience=3,\n",
    "                                                min_lr=1e-6,\n",
    "                                                verbose=1,\n",
    "                                                cooldown=3)\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "                                                filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor=monitor_name,\n",
    "                                                mode='min',\n",
    "                                                save_best_only=True,\n",
    "                                                verbose=True)\n",
    "\n",
    "for _ in range(10):\n",
    "    try:\n",
    "        history = model.fit(train_ds,\n",
    "                            epochs=num_epochs,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=val_ds,\n",
    "                            validation_steps=int(np.floor(1000/batch_size)),\n",
    "                            validation_freq=1,\n",
    "                            verbose=True,\n",
    "                            callbacks=[reduce_lr, checkpoint_callback])\n",
    "    except:\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print(\"======================== reset ==========================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train with $\\rho=32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/ji/Dropbox/Robotics/CMSC733/Project1/Phase2/Data\"\n",
    "\n",
    "# get new dataset\n",
    "train_ds2 = get_tf_dataset(root+\"/Train_Resize\",\n",
    "                          mode=\"unsupervised\",\n",
    "                          do_resize=False,\n",
    "                          rho=32)\n",
    "\n",
    "val_ds2 = get_tf_dataset(root+\"/Val_Resize\",\n",
    "                          mode=\"unsupervised\",\n",
    "                          do_resize=False,\n",
    "                          rho=32)\n",
    "\n",
    "batch_size = 8\n",
    "monitor_name = \"mae_loss\"\n",
    "checkpoint_path = f\"./chkpt/mdl_unsupervised_rho32\"\n",
    "model=get_model(mode=\"unsupervised\")\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3,\n",
    "                                              clipvalue=0.01),\n",
    "              run_eagerly=False)\n",
    "model.optimizer.learning_rate=8e-6\n",
    "num_epochs=50\n",
    "steps_per_epoch = int(np.floor(5000/batch_size))\n",
    "    # reduce learning rate when performance plateau\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=monitor_name,\n",
    "                                                factor=0.2,\n",
    "                                                patience=3,\n",
    "                                                min_lr=1e-6,\n",
    "                                                verbose=1,\n",
    "                                                cooldown=3)\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "                                                filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor=monitor_name,\n",
    "                                                mode='min',\n",
    "                                                save_best_only=True,\n",
    "                                                verbose=True)\n",
    "\n",
    "for _ in range(10):\n",
    "    try:\n",
    "        history = model.fit(train_ds2,\n",
    "                            epochs=num_epochs,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=val_ds2,\n",
    "                            validation_steps=int(np.floor(1000/batch_size)),\n",
    "                            validation_freq=1,\n",
    "                            verbose=True,\n",
    "                            callbacks=[reduce_lr, checkpoint_callback])\n",
    "    except:\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print(\"======================== reset ==========================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
